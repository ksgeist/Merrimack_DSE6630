---
title: "DESeq Analysis - 30 min data"
subtitle: "Merrimack College DSE6630: Healthcare & Life Sciences Analytics"
author: "Katherine S. Geist, PhD"
date: "22 April 2024"
output:
  html_document:
    toc: true
    toc_float: true
    theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = TRUE,
                      cache.comments = TRUE,
                      size = 13)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
# Turn off scientific notation
options(scipen=999)

# Set seed
set.seed(50009)


# Clean, set up, and load
pacman::p_unload(pacman::p_loaded(), character.only = TRUE)
rm(list = ls(all = TRUE))

pacman::p_load(here,
               tidyverse, 
               ggplot2, 
               kableExtra,
               BiocManager,
               DESeq2,
               pheatmap,
               RColorBrewer,
               vsn,
               gridExtra,
               ggrepel
            )
```

# Introduction

This code creates the Variance-Stabilizing Transformed (VST) data for the 30-min data for the __benchmarking study__ we are doing with the bumblebee chill-coma data. This is for students doing this for their Project 1 - **but you do not need to run this code**. The results have been provided to you.

## Sample Metadata
__Metadata__ refers to information about sequencing files that describe the samples. This can include information about how the samples were collected, the __phenotypes__ of the samples (the traits, physical or behavioral, that are thought to be at least partially controlled by gene expression diversity), and IDs for individuals or, in this case, colonies from which the data come.

```{r, echo=FALSE, fig.height=3}
# Load the metadata files
metadata <- read_csv("../Demo/23524047/Complete_sampleinfo.csv",
                     show_col_types = FALSE) %>% 
            as.data.frame() %>% 
            mutate_if(is.character, as.factor)

dict <- tribble(
  ~ Variable, ~ Description,
  "sampleID", "The original ID of the sequencing sample obtained",
  "Colony", "The bumblebee colony from which the indiduals sampled came",
  "Treatment", "Control vs. Chill Exposure",
  "Time", "Duration of the treatment"
)

kable(
    dict,
    format = "html",
    caption = "Table 1. Metadata of the gene expression samples.") %>%
    kable_styling(bootstrap_options = c("hover", full_width = F, full_height = F)
)
```

* We only want the samples for the 30-min experiment, so we will filter for that.

```{r, echo =FALSE}
metadata <- metadata %>% 
  filter(Time == '30m')

sampleList <- droplevels(metadata$sampleID)   # store the list of 30-min samples so that we can extract just those; dropping unused levels also well 

# check that we have 16 samples:
paste0("There are ", length(sampleList), " samples in the 30-min experiment.")
```

## Read Counts
We will be working with the __raw count__ data as __CPM (read counts per million)__ from just the 16 samples from the 30-min experiment to perform a DEG analysis. 

* Let's read in the raw counts and filter for just the 30-min samples.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
counts <- read_csv(file = "../Demo/23524047/ECK_CountData_Complete.csv") %>% 
  as.data.frame() %>% 
  select(geneID, any_of(sampleList)) 

# check the dimensions are as expected: 
paste0("There are ", ncol(counts)-1, " samples in the columns of the counts dataset with ", nrow(counts), " genes in the rows.")
```


# Conventional Method: Differential Expression Analysis using `DESeq2`

The Bioconductor package `DESeq2` is one of several such packages that exist in R, but has rapidly become one of the 'gold standards' for DE analyses. You can find more about how this package is used by looking at the [vignette](http://bioconductor.org/packages/devel/bioc/vignettes/DESeq2/inst/doc/DESeq2.html).

## Pre-processing the counts data and metadata

In short, `DESeq2` reads in the raw counts as a matrix, which must then be converted to a __design matrix__ which includes the sample metadata for each column.  Importantly, matrices should **not** contain the IDs in a column, but should be move to the __row names__ of the matrix instead. 

```{r, echo=FALSE}
# 1. Assign the `geneID` column as the rownames and then remove the `geneID` column from raw counts
rownames(counts) <- counts$geneID
counts <- counts[ ,-1]

# 2. Assign the `sampleID` column as the rownames and then remove the `sampleID` column from metadata
rownames(metadata) <- metadata$sampleID
metadata <- metadata[ ,-1]

# 3. Configure the metadata with specific column headings; make sure that the orders of the column names of the counts matrix is identical to and in the same order as the metadata matrix
# TRUE returned if these cases are satisfied
paste0("The column names of the counts matrix are present in the row names of the metadata: ", all(colnames(counts) %in% rownames(metadata)))
paste0("The names are in the same order: ", all(colnames(counts) == rownames(metadata)))

# 4. Make sure the levels of the factor(s) of interest in the metadata are using the correct reference level
# levels(as.factor(metadata$Treatment))
metadata$Treatment <- factor(metadata$Treatment, levels = c("Control", "Cold"))
```

## Make the `DESeq` Design Object

Next, make the __design object__, which contains your __model formula__ for analysis; the design formula here should **not** include time. `Treatment` is placed at the end of the formula as it is the variable of interest. We are making a `DESeqDataSet` object class used by `DeSeq2` to store the read counts, metadata, and design formula. 

```{r, message=FALSE, warning=FALSE}
dsgnObject <- DESeqDataSetFromMatrix(countData = counts, 
                                     colData = metadata,
                                     design = ~ Colony + Treatment)
dim(dsgnObject)
```

## Normalization: Variance-Stabilizing Transformation

As we currently still have raw counts in the design object, we will apply a __variance stabilizing__ transformation with a parametric fit with the variance stabilizing transform (VST). Note that all transformations have set `blind = FALSE`. We do not want the transformations to be blind to the experimental design (treatment) at this point; we expect large differential expression in some genes. Thus, we need to control for outliers by setting `blind = FALSE`.

```{r, echo = F, warning=FALSE, message=FALSE}
runVST <- function(dsgnObject, blind, fitType, makePlot = TRUE, writeTable = FALSE, writeRData = FALSE) {
  ## @dsgnObject = your DESeq2 Design Object
  ## @fitType = the type of fit you want to perform; choices are 'parametric', 'local', 'mean', 'rlog'
  ## @makePlot = TRUE/FALSE; do you want to visualize the fit?
  ## @writeTable = TRUE/FALSE; do you want to write a text file of the transformed design object (as a matrix)?
  ## @writeRData = TRUE/FALSE; do you want an RData file of the transformed design object (as a DESeq object)?

  ## Perform the VST
  
  # Check if the fitType is the regularized log:
  if(fitType == "rlog") {
    vsData <- rlog(dsgnObject, blind = blind)
  }
  ## Otherwise:
  else {
    vsData <- varianceStabilizingTransformation(dsgnObject, 
                                              blind = blind, 
                                              fitType = fitType)
  }
  
  if(makePlot == TRUE) {
    # Plot the effect of the VS transform:
    p1 <- meanSdPlot(assay(dsgnObject), plot = F)
    p1 <- p1$gg + ggtitle("Before Variance Stabilization") + 
      scale_fill_gradient(low = "cadetblue", high = "purple") + 
      theme_bw() + theme(legend.position = "bottom")
    p2 <- meanSdPlot(assay(vsData), plot = F)
    p2 <- p2$gg + ggtitle("After Variance Stabilization") + 
      scale_fill_gradient(low = "cadetblue", high = "purple") + 
      theme_bw() + theme(legend.position = "bottom")
    grid.arrange(p1, p2, nrow=1)
  }
  
  if(writeTable == TRUE) {
    # Write the data for future use, if needed:
    write.table(assay(vsData),
              file = "vst_30_min.txt",
              sep="\t", 
              quote=F, 
              row.names=T)
  }
  if(writeRData == TRUE) {
    save(vsData, file="vst_30_min.Rdata")
  }
  return(vsData)
}

runVST(dsgnObject, blind = FALSE, fitType = "parametric", makePlot = TRUE, writeTable = TRUE, writeRData = TRUE)
```


## Wald Tests for significant differential expression between conditions

The `DESeq()` function does two things roughly simultaneously. It performs normalization (median of ratios) to corrects for variance in read sequencing depth & inter-library dispersion in counts (for each gene). It also calculates the significance of coefficients with a negative binomial GLM. We will also return log-fold change for each gene based on our design formula.

##### Estimate the size factors.
A __size factor__ is effectively a count of how many reads there are in each library, sample, or batch (it can depend on the design). This is to account for those batch-level effects. 
```{r, echo = FALSE}
load("vst_30_min.Rdata")
dsgnObject <- estimateSizeFactors(dsgnObject)        ## Yes, we are overwriting our object after scaling for convenience.
```

Examine how well the scaling/normalization has worked across all of the samples:
```{r, include = TRUE, fig.width = 4.5, fig.height = 4.5, echo = FALSE}
temp <- metadata %>% 
  mutate(sampleID = rownames(metadata))

normalized_counts_long <- assay(vsData) %>% 
  data.frame() %>%
  mutate(Locus = rownames(assay(vsData))) %>% 
  pivot_longer(cols = -17, values_to = "Variance-Stabilized Expression", names_to = "sampleID")  %>% 
  full_join(temp, by = "sampleID") 

ggplot(normalized_counts_long, aes(x = sampleID, y = `Variance-Stabilized Expression`, color = Treatment)) +
  geom_boxplot() + 
  theme_classic() + 
  coord_flip() + 
  geom_hline(aes(yintercept = median(assay(vsData))), col="black", show.legend = T) +
  scale_color_manual(values=c("cadetblue", "#a8325e"))
```
Run the Wald tests:
```{r, include = TRUE, echo = FALSE, message=FALSE, warning=FALSE}
alpha <- 0.05                                                         ## Setting this for a False Discovery Rate of 5%
dispObject <- estimateDispersions(dsgnObject)                         ## Estimate the dispersions
waldObject <- nbinomWaldTest(dispObject)                              ## Use that to perform the negative binomial Wald tests
resultsDESeq <- results(waldObject,
                        alpha = alpha, 
                        pAdjustMethod = "BH")                         ## Uses Benjamini-Hochberg / FDR adjusted p-values
summary(resultsDESeq)
save(resultsDESeq, file = "DESeqResults_30_min.Rdata")                       ## Save the results
```

Not bad! Using the Wald test, we found 34 up-regulated and 13 down-regulated genes for a total of **47 differentially expressed genes.**


# Exploratory Data Analysis

## Summary statistics on the raw gene (feature) counts

```{r, echo = FALSE}
countsSummStats <- function(df, meta) {
  header <- c("Total Genes", 
              "Number Genes with >1 read count", 
              "Proportion with Nonzero Expression", 
              "Proportion with Low Expression", 
              "Number Reads: Cold-Expossed Treatment", 
              "Number Reads: Control Treatment", 
              "Total Reads Mapped", 
              "N Samples", 
              "Mean CPM per Sample")
  
  totalGenes <- nrow(df)          ## Total genes that were in the genome used for mapping
  totalCounts <- rowSums(df)
  ## Number of genes with at least 1 count:
  numNonzeroExp <- length(totalCounts[totalCounts > 0])
  propNonzeroExp <- numNonzeroExp / totalGenes
  ## How about how many genes where there are fewer than 10 reads in 90% of samples?
  lowExpression <- length(totalCounts[totalCounts < 10*ncol(df)*0.9]) 
  propLowExp <- sum(lowExpression) / totalGenes

  ## Read count by treatment
  A <- meta %>% 
    filter(Treatment == "Cold") %>% 
    rownames()
  countA <- df %>% 
    select(any_of(A)) %>% 
    sum()

  B <- meta %>% 
    filter(Treatment == "Control") %>% 
    rownames()
  countB <- df %>% 
    select(any_of(B)) %>% 
    sum()

  totalReads <- sum(df)       # Total read count
  samples <- ncol(df)         # Number of samples
  
  summStats <- as.data.frame(rbind(sprintf("%1.0f", totalGenes), 
                                   sprintf("%1.0f", numNonzeroExp), 
                                   sprintf("%1.4f", propNonzeroExp), 
                                   sprintf("%1.4f", propLowExp), 
                                   sprintf("%1.0f", countA), 
                                   sprintf("%1.0f", countB), 
                                   sprintf("%1.0f", totalReads), 
                                   sprintf("%1.0f", samples), 
                                   sprintf("%1.2f", totalReads/samples/10^6)))
  rownames(summStats) <- header
  names(summStats) <- "All Samples" 

  return(summStats)
}

summaryStatsDF <- countsSummStats(counts, metadata) 

summaryStatsDF %>% 
kable(
    format = "html",
    caption = "Summary statistics of the raw gene expression counts, Time: 30 min") %>%
    kable_styling(bootstrap_options = c("hover", full_width = F)
)
```

## Heatmap of gene expression across treatments & time points

```{r, fig.width = 5, fig.height = 4, echo = FALSE}
## Compute  pairwise correlation values for samples:
pwCorr <- cor(assay(vsData))
## Let's rename the samples to something more meaningful to us using treatment and time
rownames(pwCorr) <- paste(vsData$Treatment, vsData$Time, sep="-" )
colnames(pwCorr) <- NULL        ## No column names, thanks.

## Let's set a monochromatic color palette
colors <- colorRampPalette(brewer.pal(9, "Purples"))(255)

## Let's make our heatmap!
pheatmap(pwCorr, 
         color = colors)
```

This time we are seeing some more clustering of the chill-come and control samples, although it's still pretty messy.

## Principal Component Analysis (PCA)

```{r, warning=FALSE, message=FALSE, fig.width = 4, fig.height = 4, echo = FALSE}
#Create a PCA data frame
pca <- plotPCA(vsData, 
               intgroup = c("Treatment", "Colony"), 
               returnData = TRUE,
               ntop = 500)
percentVar <- round(100 * attr(pca, "percentVar"))

#Plot the PCA with the % variance attributable to PC1 and PC2
ggplot(pca, aes(PC1, PC2, color = Treatment, shape = Colony)) +
  geom_point(size=3, alpha = 0.85) +
  scale_color_manual(values=c("cadetblue", "#a8325e")) +
  labs(x = paste0("PC1: ",percentVar[1], "% variance"), 
       y = paste0("PC2: ",percentVar[2], "% variance"),
       title = "PCA of Gene Expression \nby Treatment + Colony") +
  xlim(-30,30) +
  ylim(-15, 15) +
  theme_bw() +
  theme(axis.text = element_text(size = 13),
        legend.position = "right")
```

### Volcano Plot of Gene Expression, 30-min Sample

```{r, warning = FALSE, echo = FALSE, message = FALSE, fig.height=6, fig.width=10}
res <- resultsDESeq %>% 
  as.data.frame() %>% 
  mutate(DEG = ifelse(log2FoldChange > 0 & padj < 0.05, "Up DEG",
                       ifelse(log2FoldChange < 0 & padj < 0.05, "Down DEG", "N.S."))) %>% 
  drop_na()    ## We have to drop the NAs for Volcano plots, unfortunately!

# Next, we would like to annotate anything with greater then 2 log-fold change in expression:
res <- res %>% 
  mutate(locus = ifelse(abs(log2FoldChange) > 3, rownames(res), ""))

res %>% 
  ggplot(aes(x = log2FoldChange, y = -log10(pvalue), label=locus, color = DEG)) + 
  geom_point(alpha = 0.85, size = 1.5) +
  scale_color_manual(values=c("cadetblue", "gray", "#a8325e")) +
  geom_text_repel(show.legend = FALSE) +
  labs(y = expression(paste(-log[10], " p-value")),
       x = expression(paste(log[2], "-fold change"))) +
  theme_classic() +
  theme(axis.text = element_text(size = 15), 
        axis.title = element_text(size = 15),
        title = element_text(size = 18),
        legend.text = element_text(size = 15)) +
  geom_vline(xintercept = c(-2, 2), col="purple")                      ## Log-fold change of 2 times
#  geom_hline(yintercept = -log10(0.05), col="darkorange")             ## Corresponds to a p-value cutoff of 0.05; original not padj though, do not display
```

#### This volcano plot looks **SO** much better! This is much more like what a canonical volcano plot looks like.


